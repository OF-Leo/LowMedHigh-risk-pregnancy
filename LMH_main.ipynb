{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkEPPGTQFuU_"
      },
      "outputs": [],
      "source": [
        "# INSTALAÇÃO DE BIBLIOTECAS\n",
        "from IPython.display import clear_output\n",
        "!pip install scikeras\n",
        "!pip install scikit-learn==1.4.2\n",
        "!pip install tensorflow\n",
        "!pip install tabulate\n",
        "!pip install seaborn\n",
        "!pip install xgboost\n",
        "!pip install imblearn\n",
        "!pip install shap\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvqAfkpiFyX5"
      },
      "outputs": [],
      "source": [
        "# BIBLIOTECAS\n",
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import xgboost as XGB\n",
        "import shap\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import HTML\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import preprocessing\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "jcaRIf5XMXyM",
        "outputId": "f7c30348-ee22-4ea1-d6c1-8c4ff4486cc3"
      },
      "outputs": [],
      "source": [
        "# LEITURA DO DATASET\n",
        "data = pd.read_csv('Maternal Health Risk Data Set.csv')\n",
        "palette = {'low risk': 'yellowgreen', 'mid risk': 'gold', 'high risk': 'firebrick'}\n",
        "paleta = ['yellowgreen', 'gold', 'firebrick']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74pxuUjSJ0cu"
      },
      "outputs": [],
      "source": [
        "# FUNÇÃO PARA A DIVISÃO DE DADOS DO DATASET 1\n",
        "def func_data_1(random_state = 42, output = True):\n",
        "  # LEITURA DO BANCO DE DADOS\n",
        "  data_1 = copy.deepcopy(data)\n",
        "\n",
        "  # DIVISÃO DOS DADOS (FEATURES E TARGET)\n",
        "  X = data_1[data_1.columns[:6]]\n",
        "  y = data_1[data_1.columns[6]]\n",
        "\n",
        "  # TRANSFORMANDO AS CLASSES EM VALORES NUMÉRICOS\n",
        "  y = y.map({'low risk': 0, 'mid risk': 1, 'high risk': 2})\n",
        "\n",
        "  # DIVISÃO DOS CONJUNTOS DE TREINO E DE TESTE\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_state, stratify = y) # 80% para treino (X_train, y_train) e 20% para teste (X_test, y_test) de forma estratificada\n",
        "  rs = random_state # garante reprodutibilidade salvando o valor randomico\n",
        "\n",
        "  # EXIBIÇÃO DE INFORMAÇÕES SOBRE O DATASET\n",
        "  print('== DATASET ORGINAL ==')\n",
        "  print('- Classes -\\n')\n",
        "  print('Baixo Risco (0):', len(data_1[data_1['RiskLevel'] == 'low risk']))\n",
        "  print('Médio Risco (1):', len(data_1[data_1['RiskLevel'] == 'mid risk']))\n",
        "  print('Alto Risco  (2):', len(data_1[data_1['RiskLevel'] == 'high risk']))\n",
        "  print(f'\\nDistribuição de targets de TREINO: {Counter(y_train)}')\n",
        "  print(f'Distribuição de targets de TESTE: {Counter(y_test)}')\n",
        "  print('\\n- Informações Adicionais -\\n')\n",
        "  data_1.info()\n",
        "  print('\\n- Tabela -\\n')\n",
        "  display(data_1.head())\n",
        "\n",
        "  if output == False:\n",
        "    clear_output()\n",
        "\n",
        "  return data_1, np.array(X_train), np.array(X_test), y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "pnVM4OCw_eKr",
        "outputId": "5a2a681e-9868-4845-ff97-14c8c112effd"
      },
      "outputs": [],
      "source": [
        "data_1, X_train, X_test, y_train, y_test = func_data_1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "xL07STmD6WuR",
        "outputId": "4964b85c-ebe1-4820-988d-948925f33e14"
      },
      "outputs": [],
      "source": [
        "# ESTATÍSTICAS DESCRITIVAS DO DATASET ORIGINAL\n",
        "# Vetores para armazenar cada registro por classe\n",
        "lowR = data_1[data_1['RiskLevel'] == 'low risk']\n",
        "mediumR = data_1[data_1['RiskLevel'] == 'mid risk']\n",
        "highR = data_1[data_1['RiskLevel'] == 'high risk']\n",
        "# Exclui linhas vazias\n",
        "lowR = lowR.reset_index(drop = True)\n",
        "mediumR = mediumR.reset_index(drop = True)\n",
        "highR = highR.reset_index(drop = True)\n",
        "\n",
        "low_discribe = pd.DataFrame(lowR.describe()).round(2)\n",
        "medium_discribe = pd.DataFrame(mediumR.describe()).round(2)\n",
        "high_discribe = pd.DataFrame(highR.describe()).round(2)\n",
        "\n",
        "discribe_all = pd.concat([low_discribe, medium_discribe, high_discribe], keys = ['Baixo Risco', 'Médio Risco', 'Alto Risco'])\n",
        "\n",
        "display(discribe_all)\n",
        "discribe_all.to_csv('Discribe_low_mid_high-Dataset_Original.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "q0nLRvtr6yVZ",
        "outputId": "77d0e29a-e2c1-41b3-989b-7ea192e4909a"
      },
      "outputs": [],
      "source": [
        "# PROPORÇÃO DE DIAGNÓSTICOS\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar('Baixo', len(lowR), color =  paleta[0])\n",
        "plt.bar('Médio', len(mediumR), color =  paleta[1])\n",
        "plt.bar('Alto', len(highR), color =  paleta[2])\n",
        "plt.title('Quantidade por Nível de Risco do Dataset Original', fontsize=14)\n",
        "plt.xlabel('Nível de Rico')\n",
        "plt.ylabel('Quantidade')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "aaSBC-AgcgiA",
        "outputId": "fa68d08c-ac4f-482a-a73e-c804c7eb3d77"
      },
      "outputs": [],
      "source": [
        "# MATRIZ DE CORRELAÇÃO DOS DADOS\n",
        "# Calcula a matriz de correlação\n",
        "dataCORR = data_1.drop(['RiskLevel'], axis = 1)\n",
        "correlation = dataCORR.corr(numeric_only=True)\n",
        "\n",
        "# Cria o heatmap\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(correlation, annot=True, fmt='0.2f',cmap='Blues')\n",
        "plt.title(\"Matriz de Correlação\", fontsize=14)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24vwX_vn7qRI",
        "outputId": "fc5dd5a3-e1e6-47da-f7c3-299949e508c0"
      },
      "outputs": [],
      "source": [
        "# HISTOGRAMAS E BOXPLOTS\n",
        "for i in range(0, len(data_1.columns) - 1 ):\n",
        "  fig, ax = plt.subplots(ncols = 2, nrows = 1, figsize = (12, 6))\n",
        "  ax[0].hist([lowR[data_1.columns[i]], mediumR[data_1.columns[i]], highR[data_1.columns[i]]], bins = 12, color = paleta, alpha = 0.7, label=['Baixo Risco', 'Médio Risco', 'Alto Risco'], histtype = 'bar')\n",
        "  ax[0].set_title(f'Distribuição de {data_1.columns[i]}', fontsize=14)\n",
        "  ax[0].set_xlabel(data_1.columns[i])\n",
        "  ax[0].set_ylabel('Frequência')\n",
        "  ax[0].legend()\n",
        "  sns.boxplot(data = data_1, x = 'RiskLevel', y = data_1.columns[i], ax = ax[1], palette = palette, hue='RiskLevel', order = ['low risk', 'mid risk', 'high risk'])\n",
        "  ax[1].set_title(f'{data_1.columns[i]} por Nível de Risco', fontsize=14)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lM2Cv3S8h9t",
        "outputId": "09254fb1-d8d3-4788-9e87-ccd54213b8ec"
      },
      "outputs": [],
      "source": [
        "# GRÁFICO DE DISPERSÃO\n",
        "for i in range(0, len(data_1.columns) - 1):\n",
        "  count = 0\n",
        "  fig, ax = plt.subplots(ncols = 5, nrows = 1, figsize = (30, 6))\n",
        "  for j in range(0, len(data_1.columns) - 1):\n",
        "    if i != j:\n",
        "      ax[count].scatter(lowR[data_1.columns[i]], lowR[data_1.columns[j]], color = palette['low risk'], label = 'Baixo risco')\n",
        "      ax[count].scatter(mediumR[data_1.columns[i]], mediumR[data_1.columns[j]], color = palette['mid risk'], label = 'Médio risco')\n",
        "      ax[count].scatter(highR[data_1.columns[i]], highR[data_1.columns[j]], color = palette['high risk'], label = 'Alto risco')\n",
        "      ax[count].set_xlabel(data_1.columns[i])\n",
        "      ax[count].set_ylabel(data_1.columns[j])\n",
        "      ax[count].set_title(f'{data_1.columns[i]} x {data_1.columns[j]}', fontsize=14)\n",
        "      ax[count].legend()\n",
        "      count += 1\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGl_tw7SWNC0"
      },
      "outputs": [],
      "source": [
        "# FUNÇÃO PARA A DIVISÃO DE DADOS DO DATASET 3\n",
        "def func_data_3(random_state = 42, output = True):\n",
        "  # LEITURA DO BANCO DE DADOS\n",
        "  data_3 = copy.deepcopy(data)\n",
        "\n",
        "  # REFINAMENTO\n",
        "  for i in range(0, len(data['Age'])):\n",
        "  # Correção do registro errado da frequência cardíaca\n",
        "    if data_3['HeartRate'][i] < 20:\n",
        "      data_3.loc[i, 'HeartRate'] = data_3['HeartRate'][i] * 10\n",
        "  # Remoção dos registros das gestantes menores de 18\n",
        "    # elif data_R['Age'][i] < 18:\n",
        "    #   data_R = data_R.drop(i, axis = 0)\n",
        "  data_3 = data_3.drop_duplicates().reset_index(drop = True) # Remove registros duplicados e exclui linhas vazias\n",
        "\n",
        "  # DIVISÃO DOS DADOS (FEATURES E TARGET)\n",
        "  X = data_3[data_3.columns[:6]]\n",
        "  y = data_3[data_3.columns[6]]\n",
        "\n",
        "  # TRANSFORMANDO AS CLASSES EM VALORES NUMÉRICOS\n",
        "  y = y.map({'low risk': 0, 'mid risk': 1, 'high risk': 2})\n",
        "\n",
        "  # DIVISÃO DOS CONJUNTOS DE TREINO E DE TESTE\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_state, stratify = y) # 80% para treino (X_train, y_train) e 20% para teste (X_test, y_test) de forma estratificada\n",
        "  rs = random_state # garante reprodutibilidade salvando o valor randomico\n",
        "\n",
        "  # ALGORITMO SMOTE\n",
        "  sm = SMOTE(random_state = random_state, k_neighbors = 5) # Configuração do SMOTE\n",
        "  X_train, y_train = sm.fit_resample(X_train, y_train) # Adição do SMOTE para o set de treinamento\n",
        "\n",
        "  # DATASET COM REGISTROS SINTÉTICOS\n",
        "  X_concat = pd.concat([X_train, X_test], axis = 0)\n",
        "  y_concat = pd.concat([y_train, y_test], axis = 0)\n",
        "  data_3 = pd.concat([X_concat, y_concat], axis = 1)\n",
        "  data_3 = data_3.replace({0: 'low risk', 1: 'mid risk', 2: 'high risk'})\n",
        "\n",
        "  # NORMALIZAÇÃO DOS DADOS\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  # EXIBIÇÃO DE INFORMAÇÕES SOBRE O DATASET\n",
        "  print('== DATASET REFINADO ==')\n",
        "  print('- Classes -\\n')\n",
        "  print('Baixo Risco (0):', len(data_3[data_3['RiskLevel'] == 'low risk']))\n",
        "  print('Médio Risco (1):', len(data_3[data_3['RiskLevel'] == 'mid risk']))\n",
        "  print('Alto Risco  (2):', len(data_3[data_3['RiskLevel'] == 'high risk']))\n",
        "  print(f'\\nDistribuição de targets de TREINO: {Counter(y_train)}')\n",
        "  print(f'Distribuição de targets de TESTE: {Counter(y_test)}')\n",
        "  print('\\n- Informações Adicionais -\\n')\n",
        "  data_3.info()\n",
        "  print('\\n- Tabela -\\n')\n",
        "  display(data_3.head())\n",
        "\n",
        "  if output == False:\n",
        "    clear_output()\n",
        "\n",
        "  return data_3, X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "szSRX3JU-379",
        "outputId": "e4f1064c-9958-4970-f77c-46e56acc6d6a"
      },
      "outputs": [],
      "source": [
        "# CHAMADA DA FUNÇÃO\n",
        "data_3, X_train, X_test, y_train, y_test = func_data_3()\n",
        "\n",
        "# DATASET NORMALIZADO\n",
        "y_train = y_train.reset_index(drop = True)\n",
        "y_test = y_test.reset_index(drop = True)\n",
        "X_concat = pd.concat([pd.DataFrame(X_train), pd.DataFrame(X_test)], axis = 0)\n",
        "y_concat = pd.concat([y_train, y_test], axis = 0)\n",
        "data_3_norm = pd.concat([X_concat, y_concat], axis = 1)\n",
        "data_3_norm.columns = data_3.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "pKRRYukXHJJ7",
        "outputId": "82861c04-4609-40b2-a821-98d4f2b3a78e"
      },
      "outputs": [],
      "source": [
        "# ESTATÍSTICAS DESCRITIVAS DO DATASET ORIGINAL\n",
        "# Vetores para armazenar as estatísticas descritivas\n",
        "lowR = data_3_norm[data_3_norm['RiskLevel'] == 0]\n",
        "mediumR = data_3_norm[data_3_norm['RiskLevel'] == 1]\n",
        "highR = data_3_norm[data_3_norm['RiskLevel'] == 2]\n",
        "\n",
        "# Exclui linhas vazias\n",
        "lowR = lowR.reset_index(drop = True)\n",
        "mediumR = mediumR.reset_index(drop = True)\n",
        "highR = highR.reset_index(drop = True)\n",
        "\n",
        "low_discribe = pd.DataFrame(lowR.describe()).round(4)\n",
        "medium_discribe = pd.DataFrame(mediumR.describe()).round(4)\n",
        "high_discribe = pd.DataFrame(highR.describe()).round(4)\n",
        "\n",
        "discribe_all = pd.concat([low_discribe, medium_discribe, high_discribe], keys = ['Baixo Risco', 'Médio Risco', 'Alto Risco'])\n",
        "\n",
        "display(discribe_all)\n",
        "discribe_all.to_csv('Discribe_low_mid_high-Dataset_Refinado+SMOTE.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "Zx3O69H3HLQE",
        "outputId": "8565831f-5fcb-4a39-b259-1ba6aa97a65c"
      },
      "outputs": [],
      "source": [
        "# PROPORÇÃO DE DIAGNÓSTICOS\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar('Baixo', len(lowR), color = paleta[0])\n",
        "plt.bar('Médio', len(mediumR), color = paleta[1])\n",
        "plt.bar('Alto', len(highR), color = paleta[2])\n",
        "plt.title('Quantidade por Nível de Risco do Dataset Original', fontsize=14)\n",
        "plt.xlabel('Nível de Rico')\n",
        "plt.ylabel('Quantidade')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "zxCaVXlFcz4X",
        "outputId": "8894aed5-5d01-4a88-b3f2-ac12582cf755"
      },
      "outputs": [],
      "source": [
        "# MATRIZ DE CORRELAÇÃO DOS DADOS\n",
        "# Calcula a matriz de correlação\n",
        "dataCORR = data_3.drop(['RiskLevel'], axis = 1)\n",
        "correlation = dataCORR.corr(numeric_only=True)\n",
        "\n",
        "# Cria o heatmap\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(correlation, annot=True, fmt='0.2f',cmap='Blues')\n",
        "plt.title(\"Matriz de Correlação\", fontsize=14)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QxC_7EwGGrSR",
        "outputId": "ec63c5d9-64b6-4466-d177-6120fb035c0e"
      },
      "outputs": [],
      "source": [
        "# HISTOGRAMAS E BOXPLOTS\n",
        "data_3_norm['RiskLevel'] = data_3_norm['RiskLevel'].map({0: 'low risk', 1: 'mid risk', 2: 'high risk'})\n",
        "for i in range(0, len(data_3.columns) - 1 ):\n",
        "  fig, ax = plt.subplots(ncols = 2, nrows = 1, figsize = (12, 6))\n",
        "  ax[0].hist([lowR[data_3.columns[i]], mediumR[data_3.columns[i]], highR[data_3.columns[i]]], bins = 12, color = paleta, alpha = 0.7, label=['Baixo Risco', 'Médio Risco', 'Alto Risco'], histtype = 'bar')\n",
        "  ax[0].set_title(f'Distribuição de {data_3.columns[i]}', fontsize=14)\n",
        "  ax[0].set_xlabel(data_3.columns[i])\n",
        "  ax[0].set_ylabel('Frequência')\n",
        "  ax[0].legend()\n",
        "  sns.boxplot(data = data_3_norm, x = 'RiskLevel', y = data_3.columns[i], ax = ax[1], palette = palette, hue='RiskLevel', order = ['low risk', 'mid risk', 'high risk'])\n",
        "  ax[1].set_title(f'{data_3.columns[i]} por Nível de Risco', fontsize=14)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZodMo9aG9wc",
        "outputId": "c724f895-dee6-4a45-e68d-d5ccc8169719"
      },
      "outputs": [],
      "source": [
        "# Vetores para armazenar cada registro normalizado por classe\n",
        "# GRÁFICO DE DISPERSÃO\n",
        "for i in range(0, len(data_3.columns) - 1):\n",
        "  count = 0\n",
        "  fig, ax = plt.subplots(ncols = 5, nrows = 1, figsize = (30, 6))\n",
        "  for j in range(0, len(data_3.columns) - 1):\n",
        "    if i != j:\n",
        "      ax[count].scatter(lowR[data_3.columns[i]], lowR[data_3.columns[j]], color = palette['low risk'], label = 'Baixo risco')\n",
        "      ax[count].scatter(mediumR[data_3.columns[i]], mediumR[data_3.columns[j]], color = palette['mid risk'], label = 'Médio risco')\n",
        "      ax[count].scatter(highR[data_3.columns[i]], highR[data_3.columns[j]], color = palette['high risk'], label = 'Alto risco')\n",
        "      ax[count].set_xlabel(data_3.columns[i])\n",
        "      ax[count].set_ylabel(data_3.columns[j])\n",
        "      ax[count].set_title(f'{data_3.columns[i]} x {data_3.columns[j]}', fontsize=14)\n",
        "      ax[count].legend()\n",
        "      count += 1\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQGfXDW9KY4C"
      },
      "source": [
        "# **MLP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzlFnywogCqP"
      },
      "source": [
        "## Método Hold-Out #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRJeeaO0gN74",
        "outputId": "0c532581-1f70-48c4-e716-7373ebb7c378"
      },
      "outputs": [],
      "source": [
        "''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "data_, X_train, X_test, y_train, y_test = func_data_3(output = False) # !!! escolha o dataset alterando o número após o func_data_ !!!\n",
        "''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "\n",
        "# TREINO E VALIDAÇÃO HOLD-OUT\n",
        "# Definição de uma função para a compilação de um modelo variável\n",
        "def build_model(hidden1, hidden2, hidden3, dropout1, dropout2, dropout3, activation, learning_rate):\n",
        "  model = Sequential([\n",
        "      Input(shape = (6,)),\n",
        "      Dense(hidden1, activation = activation),\n",
        "      Dropout(dropout1),\n",
        "      Dense(hidden2, activation = activation),\n",
        "      Dropout(dropout2),\n",
        "      Dense(hidden3, activation = activation),\n",
        "      Dropout(dropout3),\n",
        "      Dense(3, activation = 'softmax')\n",
        "      ])\n",
        "  model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "                loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                metrics = ['accuracy'])\n",
        "  return model\n",
        "\n",
        "# Hiperparâmetros para teste\n",
        "hidden1_options = [256]\n",
        "hidden2_options = [128]\n",
        "hidden3_options = [64]\n",
        "dropout1_options = [0.5]\n",
        "dropout2_options = [0.5]\n",
        "dropout3_options = [0.0]\n",
        "activation_options = ['leaky_relu']\n",
        "learning_rate_options = [0.001]\n",
        "batch_size_options = [32]\n",
        "# hidden1_options = [128, 256, 512]\n",
        "# hidden2_options = [64, 128, 256]\n",
        "# hidden3_options = [32, 64, 128]\n",
        "# dropout1_options = [0.0, 0.3, 0.5]\n",
        "# dropout2_options = [0.0, 0.3, 0.5]\n",
        "# dropout3_options = [0.0, 0.3, 0.5]\n",
        "# activation_options = ['relu', 'leaky_relu']\n",
        "# learning_rate_options = [0.01, 0.001]\n",
        "# batch_size_options = [16, 32, 48]\n",
        "\n",
        "tot = len(hidden1_options) * len(hidden2_options) * len(hidden3_options) * len(dropout1_options) * len(dropout2_options) * len(dropout3_options) * len(activation_options) * len(learning_rate_options) * len(batch_size_options)\n",
        "\n",
        "# Lista para armazenar os resultados\n",
        "results = []\n",
        "\n",
        "# Definição do Eraly Stopping\n",
        "callback_HoldOut_GS = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 20, restore_best_weights = True) # Ferramenta de early stopping\n",
        "\n",
        "count = 0\n",
        "# EXECUÇÃO DO GRID SEARCH\n",
        "for h1, h2, h3, dp1, dp2, dp3, act, lr, bs in product(hidden1_options, hidden2_options, hidden3_options, dropout1_options, dropout2_options, dropout3_options, activation_options, learning_rate_options, batch_size_options):\n",
        "  count += 1\n",
        "  print( f'Testando: hidden1 = {h1}, hidden2 = {h2}, hidden2 = {h3}, dropout1 = {dp1}, dropout1 = {dp2}, dropout1 = {dp3}, activation = {act}, learning rate = {lr}, batch_size = {bs}')\n",
        "  model = build_model(h1, h2, h3, dp1, dp2, dp3, act, lr)\n",
        "  model.fit(X_train, y_train, epochs = 300, batch_size = bs, callbacks = callback_HoldOut_GS, verbose = 0, validation_data = (X_test, y_test), shuffle = True) # Treina o modelo e avalia o desempenho com os dados de teste em cada época\n",
        "  y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  results.append(((h1, h2, h3, dp1, dp2, dp3, act, lr, bs), acc))\n",
        "  print(f'{count}/{tot}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJXzJkIYkPOM",
        "outputId": "1e8807a1-9a0b-4a5c-f242-0f92a13782c2"
      },
      "outputs": [],
      "source": [
        "# OBTER O MELHOR MODELO DA VALIDAÇÃO HOLD-OUT\n",
        "best_model = max(results, key=lambda x: x[1])\n",
        "h1, h2, h3, dp1, dp2, dp3, act, lr, bs = best_model[0]\n",
        "print(f'Melhor modelo: hidden1 = {h1}, hidden2 = {h2}, hidden2 = {h3}, dropout1 = {dp1}, dropout2 = {dp2}, dropout3 = {dp3}, activation = {act}, learning rate = {lr}, batch_size = {bs}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dykescaXK776",
        "outputId": "c0be2411-24e7-4376-974a-3d5eb2d95252"
      },
      "outputs": [],
      "source": [
        "# AVALIAR 10x O MELHOR MODELO DA VALIDAÇÃO HOLD-OUT\n",
        "final_model = build_model(h1, h2, h3, dp1, dp2, dp3, act, lr)\n",
        "\n",
        "classes = [0, 1, 2]\n",
        "nome_classes = ['baixo risco', 'médio risco', 'alto risco']\n",
        "n_classes = len(nome_classes)\n",
        "\n",
        "cf_matrix_history = list()\n",
        "accuracy_history = list()\n",
        "precision_history = list()\n",
        "precision_macro_history = list()\n",
        "recall_history = list()\n",
        "recall_macro_history = list()\n",
        "f1_history = list()\n",
        "f1_weighted_history = list()\n",
        "f1_macro_history = list()\n",
        "auc_history = list()\n",
        "\n",
        "count = 0\n",
        "for i in (0, 1, 2, 5, 10, 12, 123, 1234, 12345, 42):\n",
        "  count += 1\n",
        "  # Redefinindo os conjuntos de treino e teste\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "  data_, X_train, X_test, y_train, y_test = func_data_3(random_state = i, output = False) # !!! defina novamente o dataset a ser utilizado !!!\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "\n",
        "  history = final_model.fit(X_train, y_train, epochs = 500, batch_size = bs, callbacks = callback_HoldOut_GS, verbose = 0, validation_data = (X_test, y_test), shuffle = True)\n",
        "\n",
        "  # Salvando os valores de acurácia geral e precision, recall e f1 de cada classe\n",
        "  y_pred = np.argmax(final_model.predict(X_test), axis=1)\n",
        "\n",
        "  # salvando a matriz de confusão\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  cm = pd.DataFrame(cm, index = nome_classes, columns = nome_classes)\n",
        "  cm = cm.div(cm.sum(axis = 1), axis = 0) # normalizando a matriz de confusão\n",
        "  cf_matrix_history.append(cm)\n",
        "\n",
        "  # salvando a acurácia\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  accuracy_history.append(accuracy)\n",
        "\n",
        "  # salvando a precisão de cada classe e a macro\n",
        "  precision = precision_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  precision_history.append(precision)\n",
        "  precision = precision_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  precision_macro_history.append(precision)\n",
        "\n",
        "  # salvando a recall de cada classe e a macro\n",
        "  recall = recall_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  recall_history.append(recall)\n",
        "  recall = recall_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  recall_macro_history.append(recall)\n",
        "\n",
        "  # salvando o f1-score de cada classe, o macro e o weighted\n",
        "  f1 = f1_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  f1_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'weighted', zero_division = 0)\n",
        "  f1_weighted_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  f1_macro_history.append(f1)\n",
        "\n",
        "  # salvando a média auc macro\n",
        "  y_score = final_model.predict(X_test) # Previsões\n",
        "  y_test_bin = preprocessing.label_binarize(y_test, classes = classes) # Binarizendo as classes verdadeiras\n",
        "  auc_history.append(roc_auc_score(y_test_bin, y_score, average = 'macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F2-p_5xKMeam",
        "outputId": "ddc94fd8-7cf0-4381-f82b-115928fd5230"
      },
      "outputs": [],
      "source": [
        "# EXIBIÇÃO DAS MÉTRICAS\n",
        "print('== Resultados Gerais ==')\n",
        "print(f'Acurácia: {np.array(accuracy_history).mean():.2f} ± {np.array(accuracy_history).std():.2f}')\n",
        "print(f'F1 Weighted: {np.array(f1_weighted_history).mean():.2f} ± {np.array(f1_weighted_history).std():.2f}')\n",
        "print(f'F1 Macro: {np.array(f1_macro_history).mean():.2f} ± {np.array(f1_macro_history).std():.2f}')\n",
        "print(f'Precision: {np.array(precision_macro_history).mean():.2f} ± {np.array(precision_macro_history).std():.2f}')\n",
        "print(f'Recall: {np.array(recall_macro_history).mean():.2f} ± {np.array(recall_macro_history).std():.2f}')\n",
        "print()\n",
        "print('== Resultados por Classe ==')\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Precision da classe {nome_classes[i]}: {np.array(precision_history).mean(axis=0)[i]:.2f} ± {np.array(precision_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Recall da classe {nome_classes[i]}: {np.array(recall_history).mean(axis=0)[i]:.2f} ± {np.array(recall_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'F1 da classe {nome_classes[i]}: {np.array(f1_history).mean(axis=0)[i]:.2f} ± {np.array(f1_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "\n",
        "# EXIBIÇÃO DA MATRIZ DE CONFUSÃO\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.set_title('Matriz de Confusão')\n",
        "# Criação da matriz de confusão a partir da média obtida\n",
        "cf_matrix = np.array(cf_matrix_history).mean(axis=0)\n",
        "cm = ConfusionMatrixDisplay(confusion_matrix = cf_matrix, display_labels = nome_classes)\n",
        "# Plotando a matriz de confusão\n",
        "ax = cm.plot(ax=ax, cmap = 'Blues')\n",
        "\n",
        "# EXIBIÇÃO DA CURVA ROC E SUA AUC\n",
        "# Calculando fpr, tpr e auc para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "  fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "  roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plotagem\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(0, n_classes):\n",
        "  plt.plot(fpr[i], tpr[i], color = paleta[i], label = f'Curva ROC de {nome_classes[i]} (AUC = {roc_auc[i]:.2f})', lw = 1)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw = 1)\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.xlim([-0.02, 1.0])\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "plt.ylim([0.0, 1.02])\n",
        "plt.title('Curvas ROC por classe')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "print(f'AUC geral: {np.array(auc_history).mean():.2f} ± {np.array(auc_history).std():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dKm9fdEySdn"
      },
      "source": [
        "## Validação K-Fold #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4vnpGI0yf3Y",
        "outputId": "d6e6b141-02aa-4004-a3d7-d21802a0fa14"
      },
      "outputs": [],
      "source": [
        "# TREINO E VALIDAÇÃO CRUZADA K-FOLD\n",
        "# Hiperparâmetros para teste (os melhores do grid hold-out)\n",
        "param_grid = {\n",
        "    'model__hidden1': [h1],\n",
        "    'model__hidden2': [h2],\n",
        "    'model__hidden3': [h3],\n",
        "    'model__dropout1': [dp1],\n",
        "    'model__dropout2': [dp2],\n",
        "    'model__dropout3': [dp3],\n",
        "    'model__activation': [act],\n",
        "    'model__learning_rate': [lr],\n",
        "    'batch_size': [bs]\n",
        "}\n",
        "\n",
        "# Definição do Eraly Stopping\n",
        "callback_KFold = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy', patience = 20, restore_best_weights = True)\n",
        "\n",
        "# Criar classificador\n",
        "clf = KerasClassifier(\n",
        "    model = build_model,\n",
        "    callbacks = callback_KFold,\n",
        "    epochs = 300,\n",
        "    verbose = 0\n",
        ")\n",
        "\n",
        "# Lista para armazenar os resultados\n",
        "results = []\n",
        "\n",
        "# Aplicar GridSearchCV para K = 2, 3, ..., 5\n",
        "for i in range(1, 5):\n",
        "  K = i+1\n",
        "  print(f'Validação K-Fold com {K} folds em andamento...')\n",
        "  # Treinando o modelo no K-Fold\n",
        "  grid = GridSearchCV(estimator = clf, param_grid = param_grid, scoring = 'accuracy', cv = K, verbose = 0)\n",
        "  grid_result = grid.fit(X_train, y_train)\n",
        "  y_pred = grid.predict(X_test)\n",
        "  results.append(accuracy_score(y_test, y_pred))\n",
        "  print('Concluida.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7P4wKchWesE",
        "outputId": "d810ceda-1fb5-4b4d-8892-59ff3b2a35ad"
      },
      "outputs": [],
      "source": [
        "# Exibindo todas as acurácias\n",
        "for i in range(1, 5):\n",
        "  print(f'{i+1}-Fold, acurácia:', results[i-1])\n",
        "# Exibindo o melhor K e sua acurácia\n",
        "print(f'Melhor K = {results.index(max(results)) + 2} com acurácia = {max(results)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw_IjAlJSMeZ",
        "outputId": "254539cc-a211-4a2f-9573-4226bf1c5e79"
      },
      "outputs": [],
      "source": [
        "# AVALIAR 10x O MELHOR K DA VALIDAÇÃO K-FOLD\n",
        "K = results.index(max(results)) + 2\n",
        "\n",
        "# Definição do Eraly Stopping\n",
        "callback_KFold = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy', patience = 20, restore_best_weights = True)\n",
        "\n",
        "# Criar classificador\n",
        "clf = KerasClassifier(\n",
        "    model = build_model,\n",
        "    callbacks = callback_KFold,\n",
        "    epochs = 300,\n",
        "    verbose = 0\n",
        ")\n",
        "\n",
        "classes = [0, 1, 2]\n",
        "nome_classes = ['baixo risco', 'médio risco', 'alto risco']\n",
        "n_classes = len(nome_classes)\n",
        "\n",
        "cf_matrix_history = list()\n",
        "accuracy_history = list()\n",
        "precision_history = list()\n",
        "precision_macro_history = list()\n",
        "recall_history = list()\n",
        "recall_macro_history = list()\n",
        "f1_history = list()\n",
        "f1_weighted_history = list()\n",
        "f1_macro_history = list()\n",
        "auc_history = list()\n",
        "\n",
        "count = 0\n",
        "for i in (0, 1, 2, 5, 10, 12, 123, 1234, 12345, 42):\n",
        "  count += 1\n",
        "\n",
        "  # Redefinindo os conjuntos de treino e teste\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "  data_, X_train, X_test, y_train, y_test = func_data_3(random_state = i, output = False) # !!! defina novamente o dataset a ser utilizado !!!\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "\n",
        "  # Treinando o modelo\n",
        "  grid = GridSearchCV(estimator = clf, param_grid = param_grid, scoring = 'accuracy', cv = K, verbose = 0)\n",
        "  grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "  # Salvando os valores de acurácia geral e precision, recall e f1 de cada classe\n",
        "  y_pred = grid.predict(X_test)\n",
        "\n",
        "  # salvando a matriz de confusão\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  cm = pd.DataFrame(cm, index = nome_classes, columns = nome_classes)\n",
        "  cm = cm.div(cm.sum(axis = 1), axis = 0) # normalizando a matriz de confusão\n",
        "  cf_matrix_history.append(cm)\n",
        "\n",
        "  # salvando a acurácia\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  accuracy_history.append(accuracy)\n",
        "\n",
        "  # salvando a precisão de cada classe e a macro\n",
        "  precision = precision_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  precision_history.append(precision)\n",
        "  precision = precision_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  precision_macro_history.append(precision)\n",
        "\n",
        "  # salvando a recall de cada classe e a macro\n",
        "  recall = recall_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  recall_history.append(recall)\n",
        "  recall = recall_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  recall_macro_history.append(recall)\n",
        "\n",
        "  # salvando o f1-score de cada classe, o macro e o weighted\n",
        "  f1 = f1_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  f1_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'weighted', zero_division = 0)\n",
        "  f1_weighted_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  f1_macro_history.append(f1)\n",
        "\n",
        "  # salvando a média auc macro\n",
        "  y_score = final_model.predict(X_test) # Previsões\n",
        "  y_test_bin = preprocessing.label_binarize(y_test, classes = classes) # Binarizendo as classes verdadeiras\n",
        "  auc_history.append(roc_auc_score(y_test_bin, y_score, average = 'macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EGo5EXUqXgEG",
        "outputId": "00f4653c-338c-48bb-de1c-dc98936f56ca"
      },
      "outputs": [],
      "source": [
        "# EXIBIÇÃO DAS MÉTRICAS\n",
        "print('== Resultados Gerais ==')\n",
        "print(f'Acurácia: {np.array(accuracy_history).mean():.2f} ± {np.array(accuracy_history).std():.2f}')\n",
        "print(f'F1 Weighted: {np.array(f1_weighted_history).mean():.2f} ± {np.array(f1_weighted_history).std():.2f}')\n",
        "print(f'F1 Macro: {np.array(f1_macro_history).mean():.2f} ± {np.array(f1_macro_history).std():.2f}')\n",
        "print(f'Precision: {np.array(precision_macro_history).mean():.2f} ± {np.array(precision_macro_history).std():.2f}')\n",
        "print(f'Recall: {np.array(recall_macro_history).mean():.2f} ± {np.array(recall_macro_history).std():.2f}')\n",
        "print()\n",
        "print('== Resultados por Classe ==')\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Precision da classe {nome_classes[i]}: {np.array(precision_history).mean(axis=0)[i]:.2f} ± {np.array(precision_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Recall da classe {nome_classes[i]}: {np.array(recall_history).mean(axis=0)[i]:.2f} ± {np.array(recall_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'F1 da classe {nome_classes[i]}: {np.array(f1_history).mean(axis=0)[i]:.2f} ± {np.array(f1_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "\n",
        "# EXIBIÇÃO DA MATRIZ DE CONFUSÃO\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.set_title('Matriz de Confusão')\n",
        "# Criação da matriz de confusão a partir da média obtida\n",
        "cf_matrix = np.array(cf_matrix_history).mean(axis=0)\n",
        "cm = ConfusionMatrixDisplay(confusion_matrix = cf_matrix, display_labels = nome_classes)\n",
        "# Plotando a matriz de confusão\n",
        "ax = cm.plot(ax=ax, cmap = 'Blues')\n",
        "\n",
        "# EXIBIÇÃO DA CURVA ROC E SUA AUC\n",
        "# Calculando fpr, tpr e auc para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "  fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "  roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plotagem\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(0, n_classes):\n",
        "  plt.plot(fpr[i], tpr[i], color = paleta[i], label = f'Curva ROC de {nome_classes[i]} (AUC = {roc_auc[i]:.2f})', lw = 1)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw = 1)\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.xlim([-0.02, 1.0])\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "plt.ylim([0.0, 1.02])\n",
        "plt.title('Curvas ROC por classe')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "print(f'AUC geral: {np.array(auc_history).mean():.2f} ± {np.array(auc_history).std():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3awgg6hNuDsU"
      },
      "source": [
        "## Gráficos SHAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "kE5IVQpwuGVy",
        "outputId": "25d19b87-86e8-4e29-9067-87b023f384b7"
      },
      "outputs": [],
      "source": [
        "explainer = shap.Explainer(final_model, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "shap.summary_plot(shap_values, X_test, feature_names = data_.columns[:6])\n",
        "shap.plots.bar(shap.Explanation(values = shap_values.values, base_values = shap_values.base_values, data = X_test, feature_names = data_.columns[:6]), max_display = 6)\n",
        "\n",
        "# Inicializa o visualizador JS do SHAP\n",
        "shap.initjs()\n",
        "\n",
        "# Seleciona a instancia a ser explicada (exemplo: primeira amostra do teste)\n",
        "i = 0 # ou qualquer outro índice\n",
        "\n",
        "# Criação do gráfico\n",
        "force_plot_html = shap.plots.force(\n",
        "    base_values = shap_values.base_values[i],\n",
        "    shap_values = shap_values.values[i],\n",
        "    features = X_test[i],\n",
        "    feature_names = data_.columns[:6],\n",
        "    matplotlib = False,\n",
        "    show = False\n",
        ").html()\n",
        "\n",
        "# Exibir o gráfico corretamente no  Colab\n",
        "display(HTML(force_plot_html))\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnLlpZhNBHAv"
      },
      "source": [
        "# **Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns1fDcZFBS3T"
      },
      "source": [
        "## Hold-Out #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Vo1E9NYNCiiB",
        "outputId": "6aea554a-b2bb-4b1b-e0db-ec97adb2deb3"
      },
      "outputs": [],
      "source": [
        "''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "_, X_train, X_test, y_train, y_test = func_data_3(output = False) # !!! escolha o dataset alterando o número após o func_data_ !!!\n",
        "''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "\n",
        "# TREINO E VALIDAÇÃO HOLD-OUT\n",
        "# Hiperparâmetros para teste\n",
        "n_estimators_options = [100, 200, 300, 500] # Número de árvores na floresta\n",
        "max_depth_options = [None, 10, 20, 30] # Profundidade máxima da árvore (None significa nós expandidos até que todas as folhas sejam puras ou contenham menos min_samples_split amostras)\n",
        "min_samples_split_options = [2, 5, 10] # Número mínimo de amostras necessárias para dividir um nó interno\n",
        "min_samples_leaf_options = [1, 2, 4] # Número mínimo de amostras necessárias para estar em um nó folha\n",
        "max_features_options = ['sqrt', 'log2', 1.0] # Número de recursos a serem considerados ao procurar a melhor divisão ('sqrt' é geralmente padrão e bom)\n",
        "bootstrap_options = [True, False] # Se amostras de bootstrap são usadas ao construir árvores\n",
        "\n",
        "# Lista para armazenar os resultados\n",
        "results = []\n",
        "\n",
        "# EXECUÇÃO DO GRID SEARCH\n",
        "for n_est, m_depth, min_split, min_leaf, max_feat, bootstrap in product(n_estimators_options, max_depth_options, min_samples_split_options, min_samples_leaf_options, max_features_options, bootstrap_options):\n",
        "    print(f'Testando: n_estimators = {n_est}, max_depth = {m_depth}, min_samples_split = {min_split}, min_samples_leaf = {min_leaf}, max_features = {max_feat}, bootstrap = {bootstrap}')\n",
        "    # Instanciando o modelo com os hiperparâmetros atuais\n",
        "    model = RandomForestClassifier(n_estimators = n_est, max_depth = m_depth, min_samples_split = min_split, min_samples_leaf = min_leaf, max_features = max_feat, bootstrap = bootstrap)\n",
        "    # Treina o modelo\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Faz previsões no conjunto de teste\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calcula a acurácia\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results.append(((n_est, m_depth, min_split, min_leaf, max_feat, bootstrap), acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b4UL29ENlMt",
        "outputId": "38a7ff08-4554-4794-cd40-623d12543b3b"
      },
      "outputs": [],
      "source": [
        "# OBTER O MELHOR MODELO DA VALIDAÇÃO HOLD-OUT\n",
        "best_model = max(results, key=lambda x: x[1])\n",
        "n_est, m_depth, min_split, min_leaf, max_feat, bootstrap = best_model[0]\n",
        "print(f'Melhor modelo: n_estimators = {n_est}, max_depth = {m_depth}, min_samples_split = {min_split}, min_samples_leaf = {min_leaf}, max_features = {max_feat}, bootstrap = {bootstrap}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWadV3Y9NzdD"
      },
      "outputs": [],
      "source": [
        "# AVALIAR 10x O MELHOR MODELO DA VALIDAÇÃO HOLD-OUT\n",
        "final_model = RandomForestClassifier(n_estimators = n_est, max_depth = m_depth, min_samples_split = min_split, min_samples_leaf = min_leaf, max_features = max_feat, bootstrap = bootstrap)\n",
        "\n",
        "classes = [0, 1, 2]\n",
        "nome_classes = ['baixo risco', 'médio risco', 'alto risco']\n",
        "n_classes = len(nome_classes)\n",
        "\n",
        "cf_matrix_history = list()\n",
        "accuracy_history = list()\n",
        "precision_history = list()\n",
        "precision_macro_history = list()\n",
        "recall_history = list()\n",
        "recall_macro_history = list()\n",
        "f1_history = list()\n",
        "f1_weighted_history = list()\n",
        "f1_macro_history = list()\n",
        "auc_history = list()\n",
        "\n",
        "count = 0\n",
        "for i in (0, 1, 2, 5, 10, 12, 123, 1234, 12345, 42):\n",
        "  count += 1\n",
        "  # Redefinindo os conjuntos de treino e teste\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "  _, X_train, X_test, y_train, y_test = func_data_3(random_state = i, output = False) # !!! defina novamente o dataset a ser utilizado !!!\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "\n",
        "  history = final_model.fit(X_train, y_train)\n",
        "\n",
        "  # Salvando os valores de acurácia geral e precision, recall e f1 de cada classe\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  # salvando a matriz de confusão\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  cm = pd.DataFrame(cm, index = nome_classes, columns = nome_classes)\n",
        "  cm = cm.div(cm.sum(axis = 1), axis = 0) # normalizando a matriz de confusão\n",
        "  cf_matrix_history.append(cm)\n",
        "\n",
        "  # salvando a acurácia\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  accuracy_history.append(accuracy)\n",
        "\n",
        "  # salvando a precisão de cada classe e a macro\n",
        "  precision = precision_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  precision_history.append(precision)\n",
        "  precision = precision_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  precision_macro_history.append(precision)\n",
        "\n",
        "  # salvando a recall de cada classe e a macro\n",
        "  recall = recall_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  recall_history.append(recall)\n",
        "  recall = recall_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  recall_macro_history.append(recall)\n",
        "\n",
        "  # salvando o f1-score de cada classe, o macro e o weighted\n",
        "  f1 = f1_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  f1_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'weighted', zero_division = 0)\n",
        "  f1_weighted_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  f1_macro_history.append(f1)\n",
        "\n",
        "  # salvando a média auc macro\n",
        "  y_score = final_model.predict_proba(X_test) # Previsões de probabilidade\n",
        "  y_test_bin = preprocessing.label_binarize(y_test, classes = classes) # Binarizendo as classes verdadeiras\n",
        "  auc_history.append(roc_auc_score(y_test_bin, y_score, average = 'macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_Mv7_uNOJHd",
        "outputId": "16057ab6-496a-4e80-ac4d-a8625077fbab"
      },
      "outputs": [],
      "source": [
        "# EXIBIÇÃO DAS MÉTRICAS\n",
        "print('== Resultados Gerais ==')\n",
        "print(f'Acurácia: {np.array(accuracy_history).mean():.2f} ± {np.array(accuracy_history).std():.2f}')\n",
        "print(f'F1 Weighted: {np.array(f1_weighted_history).mean():.2f} ± {np.array(f1_weighted_history).std():.2f}')\n",
        "print(f'F1 Macro: {np.array(f1_macro_history).mean():.2f} ± {np.array(f1_macro_history).std():.2f}')\n",
        "print(f'Precision: {np.array(precision_macro_history).mean():.2f} ± {np.array(precision_macro_history).std():.2f}')\n",
        "print(f'Recall: {np.array(recall_macro_history).mean():.2f} ± {np.array(recall_macro_history).std():.2f}')\n",
        "print()\n",
        "print('== Resultados por Classe ==')\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Precision da classe {nome_classes[i]}: {np.array(precision_history).mean(axis=0)[i]:.2f} ± {np.array(precision_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Recall da classe {nome_classes[i]}: {np.array(recall_history).mean(axis=0)[i]:.2f} ± {np.array(recall_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'F1 da classe {nome_classes[i]}: {np.array(f1_history).mean(axis=0)[i]:.2f} ± {np.array(f1_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "\n",
        "# EXIBIÇÃO DA MATRIZ DE CONFUSÃO\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.set_title('Matriz de Confusão')\n",
        "# Criação da matriz de confusão a partir da média obtida\n",
        "cf_matrix = np.array(cf_matrix_history).mean(axis=0)\n",
        "cm = ConfusionMatrixDisplay(confusion_matrix = cf_matrix, display_labels = nome_classes)\n",
        "# Plotando a matriz de confusão\n",
        "ax = cm.plot(ax=ax, cmap = 'Blues')\n",
        "\n",
        "# EXIBIÇÃO DA CURVA ROC E SUA AUC\n",
        "# Calculando fpr, tpr e auc para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "  fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "  roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plotagem\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(0, n_classes):\n",
        "  plt.plot(fpr[i], tpr[i], color = paleta[i], label = f'Curva ROC de {nome_classes[i]} (AUC = {roc_auc[i]:.2f})', lw = 1)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw = 1)\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.xlim([-0.02, 1.0])\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "plt.ylim([0.0, 1.02])\n",
        "plt.title('Curvas ROC por classe')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "print(f'AUC geral: {np.array(auc_history).mean():.2f} ± {np.array(auc_history).std():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dtnrq4fBdAJ"
      },
      "source": [
        "## Validação K-Fold #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEtPW6JrOMtX",
        "outputId": "457f64e3-9ce5-44a0-9530-72f99f587883"
      },
      "outputs": [],
      "source": [
        "# TREINO E VALIDAÇÃO CRUZADA K-FOLD\n",
        "# Hiperparâmetros para teste (os melhores do grid hold-out)\n",
        "param_grid = {\n",
        "    'n_estimators': [n_est],\n",
        "    'max_depth': [m_depth],\n",
        "    'min_samples_split': [min_split],\n",
        "    'min_samples_leaf': [min_leaf],\n",
        "    'max_features': [max_feat],\n",
        "    'bootstrap': [bootstrap]\n",
        "    }\n",
        "\n",
        "# Lista para armazenar os resultados\n",
        "results = []\n",
        "\n",
        "# Aplicar GridSearchCV para K = 2, 3, ..., 5\n",
        "for i in range(1, 5):\n",
        "  K = i+1\n",
        "  print(f'Validação K-Fold com {K} folds em andamento...')\n",
        "  grid = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, scoring = 'accuracy', cv = K, verbose = 0)\n",
        "  grid_result = grid.fit(X_train, y_train)\n",
        "  y_pred = grid.predict(X_test)\n",
        "  results.append(accuracy_score(y_test, y_pred))\n",
        "  print('Concluida.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L3ffqO_PYPj",
        "outputId": "2dfabe80-ab5d-4572-fe95-6f255d0bb2fe"
      },
      "outputs": [],
      "source": [
        "# Exibindo todas as acurácias\n",
        "for i in range(1, 5):\n",
        "  print(f'{i+1}-Fold, acurácia:', results[i-1])\n",
        "# Exibindo o melhor K e sua acurácia\n",
        "print(f'Melhor K = {results.index(max(results)) + 2} com acurácia = {max(results)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfucDXIHPdoH"
      },
      "outputs": [],
      "source": [
        "# AVALIAR 10x O MELHOR K DA VALIDAÇÃO K-FOLD\n",
        "K = results.index(max(results)) + 2\n",
        "\n",
        "classes = [0, 1, 2]\n",
        "nome_classes = ['baixo risco', 'médio risco', 'alto risco']\n",
        "n_classes = len(nome_classes)\n",
        "\n",
        "cf_matrix_history = list()\n",
        "accuracy_history = list()\n",
        "precision_history = list()\n",
        "precision_macro_history = list()\n",
        "recall_history = list()\n",
        "recall_macro_history = list()\n",
        "f1_history = list()\n",
        "f1_weighted_history = list()\n",
        "f1_macro_history = list()\n",
        "auc_history = list()\n",
        "\n",
        "count = 0\n",
        "for i in (0, 1, 2, 5, 10, 12, 123, 1234, 12345, 42):\n",
        "  count += 1\n",
        "\n",
        "  # Redefinindo os conjuntos de treino e teste\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "  _, X_train, X_test, y_train, y_test = func_data_3(random_state = i, output = False) # !!! defina novamente o dataset a ser utilizado !!!\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "\n",
        "  # Treinando o modelo\n",
        "  grid = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, scoring = 'accuracy', cv = K, verbose = 0)\n",
        "  grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "  # Salvando os valores de acurácia geral e precision, recall e f1 de cada classe\n",
        "  y_pred = grid.predict(X_test)\n",
        "\n",
        "  # salvando a matriz de confusão\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  cm = pd.DataFrame(cm, index = nome_classes, columns = nome_classes)\n",
        "  cm = cm.div(cm.sum(axis = 1), axis = 0) # normalizando a matriz de confusão\n",
        "  cf_matrix_history.append(cm)\n",
        "\n",
        "  # salvando a acurácia\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  accuracy_history.append(accuracy)\n",
        "\n",
        "  # salvando a precisão de cada classe e a macro\n",
        "  precision = precision_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  precision_history.append(precision)\n",
        "  precision = precision_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  precision_macro_history.append(precision)\n",
        "\n",
        "  # salvando a recall de cada classe e a macro\n",
        "  recall = recall_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  recall_history.append(recall)\n",
        "  recall = recall_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  recall_macro_history.append(recall)\n",
        "\n",
        "  # salvando o f1-score de cada classe, o macro e o weighted\n",
        "  f1 = f1_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  f1_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'weighted', zero_division = 0)\n",
        "  f1_weighted_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  f1_macro_history.append(f1)\n",
        "\n",
        "  # salvando a média auc macro\n",
        "  y_score = final_model.predict_proba(X_test) # Previsões\n",
        "  y_test_bin = preprocessing.label_binarize(y_test, classes = classes) # Binarizendo as classes verdadeiras\n",
        "  auc_history.append(roc_auc_score(y_test_bin, y_score, average = 'macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FelC53h_PlDj",
        "outputId": "190436bb-3030-4ebb-807d-ee67992a9629"
      },
      "outputs": [],
      "source": [
        "# EXIBIÇÃO DAS MÉTRICAS\n",
        "print('== Resultados Gerais ==')\n",
        "print(f'Acurácia: {np.array(accuracy_history).mean():.2f} ± {np.array(accuracy_history).std():.2f}')\n",
        "print(f'F1 Weighted: {np.array(f1_weighted_history).mean():.2f} ± {np.array(f1_weighted_history).std():.2f}')\n",
        "print(f'F1 Macro: {np.array(f1_macro_history).mean():.2f} ± {np.array(f1_macro_history).std():.2f}')\n",
        "print(f'Precision: {np.array(precision_macro_history).mean():.2f} ± {np.array(precision_macro_history).std():.2f}')\n",
        "print(f'Recall: {np.array(recall_macro_history).mean():.2f} ± {np.array(recall_macro_history).std():.2f}')\n",
        "print()\n",
        "print('== Resultados por Classe ==')\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Precision da classe {nome_classes[i]}: {np.array(precision_history).mean(axis=0)[i]:.2f} ± {np.array(precision_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Recall da classe {nome_classes[i]}: {np.array(recall_history).mean(axis=0)[i]:.2f} ± {np.array(recall_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'F1 da classe {nome_classes[i]}: {np.array(f1_history).mean(axis=0)[i]:.2f} ± {np.array(f1_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "\n",
        "# EXIBIÇÃO DA MATRIZ DE CONFUSÃO\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.set_title('Matriz de Confusão')\n",
        "# Criação da matriz de confusão a partir da média obtida\n",
        "cf_matrix = np.array(cf_matrix_history).mean(axis=0)\n",
        "cm = ConfusionMatrixDisplay(confusion_matrix = cf_matrix, display_labels = nome_classes)\n",
        "# Plotando a matriz de confusão\n",
        "ax = cm.plot(ax=ax, cmap = 'Blues')\n",
        "\n",
        "# EXIBIÇÃO DA CURVA ROC E SUA AUC\n",
        "# Calculando fpr, tpr e auc para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "  fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "  roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plotagem\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(0, n_classes):\n",
        "  plt.plot(fpr[i], tpr[i], color = paleta[i], label = f'Curva ROC de {nome_classes[i]} (AUC = {roc_auc[i]:.2f})', lw = 1)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw = 1)\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.xlim([-0.02, 1.0])\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "plt.ylim([0.0, 1.02])\n",
        "plt.title('Curvas ROC por classe')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "print(f'AUC geral: {np.array(auc_history).mean():.2f} ± {np.array(auc_history).std():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gráficos Shap:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import xgboost as XGB\n",
        "import shap\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import HTML\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import preprocessing\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXIBIÇÃO DOS GRÁFICOS SHAP\n",
        "class_names = ['baixo risco', 'médio risco', 'alto risco']\n",
        "explainer = shap.TreeExplainer(final_model)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# Gráfico resumo geral\n",
        "shap.summary_plot(shap_values, X_test, feature_names = np.array(data.columns[:6]), plot_type = 'bar', show = False, class_names = class_names, color = plt.get_cmap(\"tab20c\"))\n",
        "plt.title(\"Gráfico Resumo das Classes\")\n",
        "plt.show()\n",
        "print('=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x')\n",
        "\n",
        "# Gráficos de resumo, barra e de força de cada classe\n",
        "instance_index = 0 # Seleciona a instancia a ser explicada (exemplo: primeira linha do teste (X_test[0]))\n",
        "for i in range(0, len(class_names)):\n",
        "  shap.summary_plot(shap_values[:, :, i], X_test, feature_names = np.array(data.columns[:6]), show = False) # quanto mais para a direita mais a influencia para a classe i\n",
        "  plt.title(f'Gráfico Resumo da classe {class_names[i]}')\n",
        "  plt.show()\n",
        "\n",
        "  shap.plots.bar(shap.Explanation(values = shap_values[:, :, i], base_values = shap_values.base_values, data = X_test, feature_names = np.array(data.columns[:6])), max_display = 6, show = False)\n",
        "  plt.title(f'Gráfico de Barra da classe {class_names[i]}')\n",
        "  plt.show()\n",
        "\n",
        "  # Escolhe a classe que você quer explicar (por exemplo, a classe 0)\n",
        "  class_to_explain = i\n",
        "\n",
        "  # SHAP values para a instância e classe escolhida\n",
        "  shap_values_instance_class = shap_values[instance_index, :, class_to_explain]\n",
        "\n",
        "  # Base value (expected_value) para a classe escolhida\n",
        "  base_value_for_class = shap_values.base_values[class_to_explain]\n",
        "\n",
        "  # Valores das features para a instância escolhida\n",
        "  feature_values_instance = X_test[instance_index]\n",
        "\n",
        "  explanation_for_instance = shap.Explanation(\n",
        "      values = shap_values_instance_class,\n",
        "      base_values = base_value_for_class,\n",
        "      data = feature_values_instance,\n",
        "      feature_names = np.array(data.columns[:6])\n",
        "  )\n",
        "  shap.plots.force(explanation_for_instance, matplotlib = True, show = False)\n",
        "  plt.title(f'Gráfico de Força da classe {class_names[i]}')\n",
        "  plt.show()\n",
        "  print('=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw1m9Ecwe4__"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTyi-OpdfBIn"
      },
      "source": [
        "## Método Hold-Out #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMYMSYehyw_w",
        "outputId": "23ffeb74-6ac0-455f-8a0f-9f84898904f8"
      },
      "outputs": [],
      "source": [
        "''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "_, X_train, X_test, y_train, y_test = func_data_3(output = False) # !!! escolha o dataset alterando o número após o func_data_ !!!\n",
        "''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "\n",
        "# TREINO E VALIDAÇÃO HOLD-OUT\n",
        "# Hiperparâmetros para teste\n",
        "C_options = [0.1, 1, 10, 100] # Parâmetro de regularização\n",
        "kernel_options = ['linear', 'poly', 'rbf', 'sigmoid'] # Tipo de kernel\n",
        "gamma_options = ['scale', 'auto'] # Coeficiente do kernel (para 'rbf', 'poly' e 'sigmoid')\n",
        "degree_options = [2, 3, 4] # Grau do polinômio para o kernel 'poly'\n",
        "\n",
        "# Lista para armazenar os resultados\n",
        "results = []\n",
        "\n",
        "# EXECUÇÃO DO GRID SEARCH\n",
        "for C, kernel, gamma, degree in product(C_options, kernel_options, gamma_options, degree_options):\n",
        "    # Ajuste para evitar combinações inválidas (degree só se aplica a kernel='poly')\n",
        "    if kernel != 'poly' and degree != degree_options[0]: # Usamos o primeiro valor como padrão quando não é poly\n",
        "        continue\n",
        "\n",
        "    print(f'Testando: C = {C}, kernel = {kernel}, gamma = {gamma}, degree = {degree}')\n",
        "\n",
        "    # Criação do modelo SVM com os hiperparâmetros atuais\n",
        "    if kernel == 'poly':\n",
        "        model = SVC(C = C, kernel = kernel, gamma = gamma, degree = degree, probability = True)\n",
        "    else:\n",
        "        model = SVC(C = C, kernel = kernel, gamma = gamma, probability = True)\n",
        "\n",
        "    # Treina o modelo com os dados de treino\n",
        "    history = model.fit(X_train, y_train)\n",
        "\n",
        "    # Faz previsões nos dados de teste\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Avalia a acurácia\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results.append(((C, kernel, gamma, degree), acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gznrq_o0W_z",
        "outputId": "85aa55a3-17c9-4aad-f8db-8dce24dc7826"
      },
      "outputs": [],
      "source": [
        "# OBTER O MELHOR MODELO DA VALIDAÇÃO HOLD-OUT\n",
        "best_model = max(results, key=lambda x: x[1])\n",
        "C, kernel, gamma, degree = best_model[0]\n",
        "if kernel == 'poly':\n",
        "  print(f'Melhor modelo: C = {C}, kernel = {kernel}, gamma = {gamma}, degree = {degree}')\n",
        "else:\n",
        "  print(f'Melhor modelo: C = {C}, kernel = {kernel}, gamma = {gamma}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXmVnDWJ0pt0"
      },
      "outputs": [],
      "source": [
        "# AVALIAR 10x O MELHOR MODELO DA VALIDAÇÃO HOLD-OUT\n",
        "if kernel == 'poly':\n",
        "  final_model = SVC(C = C, kernel = kernel, gamma = gamma, degree = degree, probability = True)\n",
        "else:\n",
        "  final_model = SVC(C = C, kernel = kernel, gamma = gamma, probability = True)\n",
        "\n",
        "classes = [0, 1, 2]\n",
        "nome_classes = ['baixo risco', 'médio risco', 'alto risco']\n",
        "n_classes = len(nome_classes)\n",
        "\n",
        "cf_matrix_history = list()\n",
        "accuracy_history = list()\n",
        "precision_history = list()\n",
        "precision_macro_history = list()\n",
        "recall_history = list()\n",
        "recall_macro_history = list()\n",
        "f1_history = list()\n",
        "f1_weighted_history = list()\n",
        "f1_macro_history = list()\n",
        "auc_history = list()\n",
        "\n",
        "count = 0\n",
        "for i in (0, 1, 2, 5, 10, 12, 123, 1234, 12345, 42):\n",
        "  count += 1\n",
        "  # Redefinindo os conjuntos de treino e teste\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "  _, X_train, X_test, y_train, y_test = func_data_3(random_state = i, output = False) # !!! defina novamente o dataset a ser utilizado !!!\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "\n",
        "  history = final_model.fit(X_train, y_train)\n",
        "\n",
        "  # Salvando os valores de acurácia geral e precision, recall e f1 de cada classe\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  # salvando a matriz de confusão\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  cm = pd.DataFrame(cm, index = nome_classes, columns = nome_classes)\n",
        "  cm = cm.div(cm.sum(axis = 1), axis = 0) # normalizando a matriz de confusão\n",
        "  cf_matrix_history.append(cm)\n",
        "\n",
        "  # salvando a acurácia\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  accuracy_history.append(accuracy)\n",
        "\n",
        "  # salvando a precisão de cada classe e a macro\n",
        "  precision = precision_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  precision_history.append(precision)\n",
        "  precision = precision_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  precision_macro_history.append(precision)\n",
        "\n",
        "  # salvando a recall de cada classe e a macro\n",
        "  recall = recall_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  recall_history.append(recall)\n",
        "  recall = recall_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  recall_macro_history.append(recall)\n",
        "\n",
        "  # salvando o f1-score de cada classe, o macro e o weighted\n",
        "  f1 = f1_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  f1_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'weighted', zero_division = 0)\n",
        "  f1_weighted_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  f1_macro_history.append(f1)\n",
        "\n",
        "  # salvando a média auc macro\n",
        "  y_score = final_model.predict_proba(X_test) # Previsões\n",
        "  y_test_bin = preprocessing.label_binarize(y_test, classes = classes) # Binarizendo as classes verdadeiras\n",
        "  auc_history.append(roc_auc_score(y_test_bin, y_score, average = 'macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEnx_5J007lA",
        "outputId": "9345f847-de57-489d-f22e-1cf78c9fc70b"
      },
      "outputs": [],
      "source": [
        "# EXIBIÇÃO DAS MÉTRICAS\n",
        "print('== Resultados Gerais ==')\n",
        "print(f'Acurácia: {np.array(accuracy_history).mean():.2f} ± {np.array(accuracy_history).std():.2f}')\n",
        "print(f'F1 Weighted: {np.array(f1_weighted_history).mean():.2f} ± {np.array(f1_weighted_history).std():.2f}')\n",
        "print(f'F1 Macro: {np.array(f1_macro_history).mean():.2f} ± {np.array(f1_macro_history).std():.2f}')\n",
        "print(f'Precision: {np.array(precision_macro_history).mean():.2f} ± {np.array(precision_macro_history).std():.2f}')\n",
        "print(f'Recall: {np.array(recall_macro_history).mean():.2f} ± {np.array(recall_macro_history).std():.2f}')\n",
        "print()\n",
        "print('== Resultados por Classe ==')\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Precision da classe {nome_classes[i]}: {np.array(precision_history).mean(axis=0)[i]:.2f} ± {np.array(precision_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Recall da classe {nome_classes[i]}: {np.array(recall_history).mean(axis=0)[i]:.2f} ± {np.array(recall_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'F1 da classe {nome_classes[i]}: {np.array(f1_history).mean(axis=0)[i]:.2f} ± {np.array(f1_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "\n",
        "# EXIBIÇÃO DA MATRIZ DE CONFUSÃO\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.set_title('Matriz de Confusão')\n",
        "# Criação da matriz de confusão a partir da média obtida\n",
        "cf_matrix = np.array(cf_matrix_history).mean(axis=0)\n",
        "cm = ConfusionMatrixDisplay(confusion_matrix = cf_matrix, display_labels = nome_classes)\n",
        "# Plotando a matriz de confusão\n",
        "ax = cm.plot(ax=ax, cmap = 'Blues')\n",
        "\n",
        "# EXIBIÇÃO DA CURVA ROC E SUA AUC\n",
        "# Calculando fpr, tpr e auc para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "  fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "  roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plotagem\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(0, n_classes):\n",
        "  plt.plot(fpr[i], tpr[i], color = paleta[i], label = f'Curva ROC de {nome_classes[i]} (AUC = {roc_auc[i]:.2f})', lw = 1)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw = 1)\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.xlim([-0.02, 1.0])\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "plt.ylim([0.0, 1.02])\n",
        "plt.title('Curvas ROC por classe')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "print(f'AUC geral: {np.array(auc_history).mean():.2f} ± {np.array(auc_history).std():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RzMqrFafEtL"
      },
      "source": [
        "## Validação K-Fold #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iZl-v0u1NlK",
        "outputId": "48f1e924-3e50-4e8f-bf64-cf0b4cdaab75"
      },
      "outputs": [],
      "source": [
        "# TREINO E VALIDAÇÃO CRUZADA K-FOLD\n",
        "# Hiperparâmetros para teste (os melhores do grid hold-out)\n",
        "if kernel == 'poly':\n",
        "  param_grid = {\n",
        "        'kernel': ['poly'],\n",
        "        'C': [C],\n",
        "        'gamma': [gamma],\n",
        "        'degree': [degree]\n",
        "    }\n",
        "else:\n",
        "  param_grid = {\n",
        "        'kernel': [kernel],\n",
        "        'C': [C],\n",
        "        'gamma': [gamma]\n",
        "    }\n",
        "\n",
        "# Lista para armazenar os resultados\n",
        "results = []\n",
        "\n",
        "# Aplicar GridSearchCV para K = 2, 3, ..., 5\n",
        "for i in range(1, 5):\n",
        "  K = i+1\n",
        "  print(f'Validação K-Fold com {K} folds em andamento...')\n",
        "  grid = GridSearchCV(estimator = SVC(), param_grid = param_grid, scoring = 'accuracy', cv = K, verbose = 0)\n",
        "  grid_result = grid.fit(X_train, y_train)\n",
        "  y_pred = grid.predict(X_test)\n",
        "  results.append(accuracy_score(y_test, y_pred))\n",
        "  print('Concluida.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcyxKwWO2kNh",
        "outputId": "d8724476-9ea5-4273-e42d-b0bf4eb2492b"
      },
      "outputs": [],
      "source": [
        "# Exibindo todas as acurácias\n",
        "for i in range(1, 5):\n",
        "  print(f'{i+1}-Fold, acurácia:', results[i-1])\n",
        "# Exibindo o melhor K e sua acurácia\n",
        "print(f'Melhor K = {results.index(max(results)) + 2} com acurácia = {max(results)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_gbAxRn2mlU"
      },
      "outputs": [],
      "source": [
        "# AVALIAR 10x O MELHOR K DA VALIDAÇÃO K-FOLD\n",
        "K = results.index(max(results)) + 2\n",
        "\n",
        "classes = [0, 1, 2]\n",
        "nome_classes = ['baixo risco', 'médio risco', 'alto risco']\n",
        "n_classes = len(nome_classes)\n",
        "\n",
        "cf_matrix_history = list()\n",
        "accuracy_history = list()\n",
        "precision_history = list()\n",
        "precision_macro_history = list()\n",
        "recall_history = list()\n",
        "recall_macro_history = list()\n",
        "f1_history = list()\n",
        "f1_weighted_history = list()\n",
        "f1_macro_history = list()\n",
        "auc_history = list()\n",
        "\n",
        "count = 0\n",
        "for i in (0, 1, 2, 5, 10, 12, 123, 1234, 12345, 42):\n",
        "  count += 1\n",
        "\n",
        "  # Redefinindo os conjuntos de treino e teste\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "  _, X_train, X_test, y_train, y_test = func_data_3(random_state = i, output = False) # !!! defina novamente o dataset a ser utilizado !!!\n",
        "  ''' === DEFINIÇÃO DO DATASET A SER UTILIZADO ==='''\n",
        "\n",
        "  # Treinando o modelo\n",
        "  grid = GridSearchCV(estimator = SVC(), param_grid = param_grid, scoring = 'accuracy', cv = K, verbose = 0)\n",
        "  grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "  # Salvando os valores de acurácia geral e precision, recall e f1 de cada classe\n",
        "  y_pred = grid.predict(X_test)\n",
        "\n",
        "  # salvando a matriz de confusão\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  cm = pd.DataFrame(cm, index = nome_classes, columns = nome_classes)\n",
        "  cm = cm.div(cm.sum(axis = 1), axis = 0) # normalizando a matriz de confusão\n",
        "  cf_matrix_history.append(cm)\n",
        "\n",
        "  # salvando a acurácia\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  accuracy_history.append(accuracy)\n",
        "\n",
        "  # salvando a precisão de cada classe e a macro\n",
        "  precision = precision_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  precision_history.append(precision)\n",
        "  precision = precision_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  precision_macro_history.append(precision)\n",
        "\n",
        "  # salvando a recall de cada classe e a macro\n",
        "  recall = recall_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  recall_history.append(recall)\n",
        "  recall = recall_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  recall_macro_history.append(recall)\n",
        "\n",
        "  # salvando o f1-score de cada classe, o macro e o weighted\n",
        "  f1 = f1_score(y_test, y_pred, average = None, zero_division = 0)\n",
        "  f1_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'weighted', zero_division = 0)\n",
        "  f1_weighted_history.append(f1)\n",
        "  f1 = f1_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
        "  f1_macro_history.append(f1)\n",
        "\n",
        "  # salvando a média auc macro\n",
        "  y_score = final_model.predict_proba(X_test) # Previsões\n",
        "  y_test_bin = preprocessing.label_binarize(y_test, classes = classes) # Binarizendo as classes verdadeiras\n",
        "  auc_history.append(roc_auc_score(y_test_bin, y_score, average = 'macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ML58x7x2rrl",
        "outputId": "6e4f02ec-248f-4397-9f2c-9b8b23ac27d2"
      },
      "outputs": [],
      "source": [
        "# EXIBIÇÃO DAS MÉTRICAS\n",
        "print('== Resultados Gerais ==')\n",
        "print(f'Acurácia: {np.array(accuracy_history).mean():.2f} ± {np.array(accuracy_history).std():.2f}')\n",
        "print(f'F1 Weighted: {np.array(f1_weighted_history).mean():.2f} ± {np.array(f1_weighted_history).std():.2f}')\n",
        "print(f'F1 Macro: {np.array(f1_macro_history).mean():.2f} ± {np.array(f1_macro_history).std():.2f}')\n",
        "print(f'Precision: {np.array(precision_macro_history).mean():.2f} ± {np.array(precision_macro_history).std():.2f}')\n",
        "print(f'Recall: {np.array(recall_macro_history).mean():.2f} ± {np.array(recall_macro_history).std():.2f}')\n",
        "print()\n",
        "print('== Resultados por Classe ==')\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Precision da classe {nome_classes[i]}: {np.array(precision_history).mean(axis=0)[i]:.2f} ± {np.array(precision_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'Recall da classe {nome_classes[i]}: {np.array(recall_history).mean(axis=0)[i]:.2f} ± {np.array(recall_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "for i in range(0, n_classes):\n",
        "  print(f'F1 da classe {nome_classes[i]}: {np.array(f1_history).mean(axis=0)[i]:.2f} ± {np.array(f1_history).std(axis=0)[i]:.2f}')\n",
        "print()\n",
        "\n",
        "# EXIBIÇÃO DA MATRIZ DE CONFUSÃO\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.set_title('Matriz de Confusão')\n",
        "# Criação da matriz de confusão a partir da média obtida\n",
        "cf_matrix = np.array(cf_matrix_history).mean(axis=0)\n",
        "cm = ConfusionMatrixDisplay(confusion_matrix = cf_matrix, display_labels = nome_classes)\n",
        "# Plotando a matriz de confusão\n",
        "ax = cm.plot(ax=ax, cmap = 'Blues')\n",
        "\n",
        "# EXIBIÇÃO DA CURVA ROC E SUA AUC\n",
        "# Calculando fpr, tpr e auc para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "  fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "  roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plotagem\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(0, n_classes):\n",
        "  plt.plot(fpr[i], tpr[i], color = paleta[i], label = f'Curva ROC de {nome_classes[i]} (AUC = {roc_auc[i]:.2f})', lw = 1)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw = 1)\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.xlim([-0.02, 1.0])\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "plt.ylim([0.0, 1.02])\n",
        "plt.title('Curvas ROC por classe')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "print(f'AUC geral: {np.array(auc_history).mean():.2f} ± {np.array(auc_history).std():.2f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nWdp7HEALlAr",
        "S5hIr9CD4rrV",
        "RF5xfbgfP6GH",
        "Pr8yJr_2GTS9",
        "GQGfXDW9KY4C",
        "3dKm9fdEySdn",
        "3awgg6hNuDsU",
        "MnLlpZhNBHAv",
        "ns1fDcZFBS3T",
        "6Dtnrq4fBdAJ",
        "uVQucZdOQsoV",
        "YRe_spUqVPIZ",
        "KYP-UXzQVRvH",
        "hw1m9Ecwe4__",
        "iTyi-OpdfBIn",
        "8RzMqrFafEtL",
        "VBuUeU5v5Xkc",
        "pHl7-Tc85c3N",
        "J-tod0ie5gtW",
        "AREMO87EWWJp",
        "1liQtd5MWnwZ",
        "nm5Cqyqukhy_",
        "XIOAthrjXqKt",
        "biHSk-FPIV6O",
        "CK1DJHwbjwHp",
        "xmKxJ-YqymFC",
        "y0FCICYiqnhl"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "undefined.undefined.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
